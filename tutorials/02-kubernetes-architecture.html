<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kubernetes Architecture Explained - Master and Worker Nodes | K8s Tutorial #2</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="../blog-styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        /* Wider container for tutorials */
        .blog-post-detail {
            max-width: 1200px !important;
        }
        .blog-post-detail .container {
            max-width: 1200px !important;
        }
        .post-content {
            max-width: 100% !important;
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" id="navbar">
        <div class="container">
            <div class="nav-brand">
                <a href="../index.html">
                    <span class="brand-icon">âš¡</span>
                    DevSecOpsSolution<span class="highlight">.in</span>
                </a>
            </div>
            <button class="nav-toggle" id="navToggle">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu" id="navMenu">
                <li><a href="../index.html#home" class="nav-link">Home</a></li>
                <li><a href="../k8s-tutorials.html" class="nav-link">K8s Tutorials</a></li>
                <li><a href="../blog.html" class="nav-link">Blog</a></li>
                <li><a href="../index.html#contact" class="nav-link">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Blog Post Content -->
    <article class="blog-post-detail">
        <div class="container">
            <div class="post-header">
                <a href="../k8s-tutorials.html" class="back-link">
                    <i class="fas fa-arrow-left"></i> Back to Tutorials
                </a>
                <div class="post-icon">ğŸ—ï¸</div>
                <h1 class="post-title">Kubernetes Architecture Explained â€” Master and Worker Nodes</h1>
                <div class="post-meta">
                    <span><i class="fas fa-bookmark"></i> Tutorial #2 of 20</span>
                    <span><i class="fas fa-signal"></i> Beginner</span>
                    <span><i class="far fa-clock"></i> 35 min read</span>
                    <span><i class="fas fa-code"></i> Hands-On Included</span>
                </div>
            </div>
            
            <div class="post-content">
                <h3 style="color: #667eea; margin-top: 0;">ğŸ¯ What You'll Learn</h3>
                <ul style="line-height: 2;">
                    <li>Complete Kubernetes architecture from 10,000-foot view to deep dive</li>
                    <li>Control Plane components in detail (API Server, etcd, Scheduler, Controller Manager)</li>
                    <li>Worker Node components deep dive (kubelet, kube-proxy, Container Runtime)</li>
                    <li>How components communicate (complete request flow)</li>
                    <li>API Server request lifecycle and authentication/authorization</li>
                    <li>etcd internals and why it's critical</li>
                    <li>Scheduler algorithm and decision-making process</li>
                    <li>All controller types and their responsibilities</li>
                    <li>kubelet internals and pod lifecycle management</li>
                    <li>Network flow and kube-proxy modes (iptables vs IPVS)</li>
                    <li>High availability architecture patterns</li>
                    <li>Troubleshooting each component</li>
                    <li>Hands-on cluster exploration with real commands</li>
                </ul>
            </div>

            <h2>ğŸ—ï¸ The Big Picture</h2>

            <p>Think of Kubernetes as a <strong>city</strong>:</p>
            <ul>
                <li><strong>Control Plane</strong> = City Hall (makes decisions, keeps records)</li>
                <li><strong>Worker Nodes</strong> = Buildings (where actual work happens)</li>
                <li><strong>Pods</strong> = Apartments (where applications live)</li>
            </ul>

            <div style="background: #2d3748; color: #e2e8f0; padding: 25px; border-radius: 10px; margin: 30px 0;">
                <h3 style="color: #90cdf4; margin-top: 0;">ğŸ¨ Kubernetes Cluster Architecture</h3>
                <pre style="background: #1a202c; padding: 20px; border-radius: 5px; overflow-x: auto; font-size: 0.85rem; line-height: 1.4;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CONTROL PLANE                                â”‚
â”‚                      (Master Node / Brain)                           â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  API Server  â”‚  â”‚   Scheduler  â”‚  â”‚  Controller  â”‚             â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚   Manager    â”‚             â”‚
â”‚  â”‚  (Gateway)   â”‚  â”‚  (Assigns    â”‚  â”‚  (Maintains  â”‚             â”‚
â”‚  â”‚              â”‚  â”‚   Pods to    â”‚  â”‚   Desired    â”‚             â”‚
â”‚  â”‚              â”‚  â”‚   Nodes)     â”‚  â”‚   State)     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                 â”‚                  â”‚                      â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                           â”‚                                         â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                    â”‚     etcd      â”‚                                â”‚
â”‚                    â”‚  (Database)   â”‚                                â”‚
â”‚                    â”‚  Stores all   â”‚                                â”‚
â”‚                    â”‚  cluster data â”‚                                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ (Network)
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
        â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WORKER NODE 1 â”‚  â”‚ WORKER NODE 2 â”‚  â”‚ WORKER NODE 3 â”‚
â”‚               â”‚  â”‚               â”‚  â”‚               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚  kubelet  â”‚ â”‚  â”‚ â”‚  kubelet  â”‚ â”‚  â”‚ â”‚  kubelet  â”‚ â”‚
â”‚ â”‚ (Agent)   â”‚ â”‚  â”‚ â”‚ (Agent)   â”‚ â”‚  â”‚ â”‚ (Agent)   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚               â”‚  â”‚               â”‚  â”‚               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚kube-proxy â”‚ â”‚  â”‚ â”‚kube-proxy â”‚ â”‚  â”‚ â”‚kube-proxy â”‚ â”‚
â”‚ â”‚(Network)  â”‚ â”‚  â”‚ â”‚(Network)  â”‚ â”‚  â”‚ â”‚(Network)  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚               â”‚  â”‚               â”‚  â”‚               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚Container  â”‚ â”‚  â”‚ â”‚Container  â”‚ â”‚  â”‚ â”‚Container  â”‚ â”‚
â”‚ â”‚ Runtime   â”‚ â”‚  â”‚ â”‚ Runtime   â”‚ â”‚  â”‚ â”‚ Runtime   â”‚ â”‚
â”‚ â”‚ (Docker)  â”‚ â”‚  â”‚ â”‚(containerdâ”‚ â”‚  â”‚ â”‚ (CRI-O)   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚               â”‚  â”‚               â”‚  â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Pod 1   â”‚  â”‚  â”‚  â”‚ Pod 3   â”‚  â”‚  â”‚  â”‚ Pod 5   â”‚  â”‚
â”‚  â”‚ Pod 2   â”‚  â”‚  â”‚  â”‚ Pod 4   â”‚  â”‚  â”‚  â”‚ Pod 6   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
            </div>

            <h2>ğŸ›ï¸ Control Plane Components</h2>

            <p>The Control Plane is the <strong>brain</strong> of Kubernetes. It makes global decisions about the cluster and detects/responds to cluster events.</p>

            <h3 style="color: #667eea;">1. API Server (kube-apiserver) - The Heart of Kubernetes</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p style="font-size: 1.1rem; line-height: 1.8;"><strong>Role:</strong> The API Server is the central management entity and the ONLY component that directly interacts with etcd. It's the front door to Kubernetes - all communication goes through it.</p>
                
                <p><strong>Analogy:</strong> Like a receptionist at a hotel - everyone talks to them first, and they coordinate with all other departments!</p>
                
                <h4 style="color: #90cdf4; margin-top: 20px;">Core Responsibilities:</h4>
                <ul style="line-height: 2;">
                    <li><strong>Exposes the Kubernetes API:</strong> RESTful HTTP API (typically on port 6443)</li>
                    <li><strong>Authentication:</strong> Verifies who you are (certificates, tokens, basic auth)</li>
                    <li><strong>Authorization:</strong> Checks what you're allowed to do (RBAC, ABAC, Webhook)</li>
                    <li><strong>Admission Control:</strong> Validates and mutates requests before persisting</li>
                    <li><strong>Validation:</strong> Ensures requests are properly formatted</li>
                    <li><strong>etcd Interface:</strong> Only component that talks to etcd directly</li>
                    <li><strong>Watch Mechanism:</strong> Allows components to watch for changes</li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">API Server Request Lifecycle:</h4>
                <div style="background: #2d3748; color: #e2e8f0; padding: 20px; border-radius: 8px; margin-top: 15px;">
                    <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto; line-height: 1.6;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         API Server Request Processing Pipeline              â”‚
â”‚                                                              â”‚
â”‚  1. HTTP Request arrives                                    â”‚
â”‚     â†“                                                        â”‚
â”‚  2. Authentication (Who are you?)                           â”‚
â”‚     â€¢ X.509 Client Certificates                             â”‚
â”‚     â€¢ Bearer Tokens (ServiceAccount tokens)                 â”‚
â”‚     â€¢ Basic Auth (username/password)                        â”‚
â”‚     â€¢ OpenID Connect (OIDC)                                 â”‚
â”‚     â†“                                                        â”‚
â”‚  3. Authorization (What can you do?)                        â”‚
â”‚     â€¢ RBAC (Role-Based Access Control) â† Most common       â”‚
â”‚     â€¢ ABAC (Attribute-Based Access Control)                 â”‚
â”‚     â€¢ Webhook (External authorization)                      â”‚
â”‚     â€¢ Node (Special authorization for kubelets)             â”‚
â”‚     â†“                                                        â”‚
â”‚  4. Admission Control (Should we allow this?)               â”‚
â”‚     Mutating Admission:                                     â”‚
â”‚     â€¢ Add default values                                    â”‚
â”‚     â€¢ Inject sidecars                                       â”‚
â”‚     â€¢ Modify resource requests                              â”‚
â”‚     â†“                                                        â”‚
â”‚     Validating Admission:                                   â”‚
â”‚     â€¢ Enforce policies                                      â”‚
â”‚     â€¢ Check quotas                                          â”‚
â”‚     â€¢ Validate configurations                               â”‚
â”‚     â†“                                                        â”‚
â”‚  5. Validation (Is the request valid?)                      â”‚
â”‚     â€¢ Schema validation                                     â”‚
â”‚     â€¢ Field validation                                      â”‚
â”‚     â†“                                                        â”‚
â”‚  6. Persist to etcd                                         â”‚
â”‚     â€¢ Write to etcd                                         â”‚
â”‚     â€¢ Get confirmation                                      â”‚
â”‚     â†“                                                        â”‚
â”‚  7. Return Response                                         â”‚
â”‚     â€¢ Success (200, 201)                                    â”‚
â”‚     â€¢ Error (400, 401, 403, 404, 500)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">Example: Creating a Pod</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># When you run:
kubectl create -f pod.yaml

# Detailed flow:
1. kubectl reads pod.yaml and sends HTTP POST to API Server
   POST /api/v1/namespaces/default/pods
   
2. API Server: Authentication
   - Checks your kubeconfig certificate
   - Validates it's signed by cluster CA
   - Extracts your username/groups
   âœ… Authenticated as "user@example.com"

3. API Server: Authorization (RBAC)
   - Checks: Can "user@example.com" CREATE pods in "default" namespace?
   - Looks up RoleBindings and ClusterRoleBindings
   - Finds: User has "edit" role in default namespace
   âœ… Authorized

4. API Server: Mutating Admission
   - PodPreset: Injects environment variables
   - ServiceAccount: Adds default service account if not specified
   - ResourceQuota: Checks namespace quotas
   âœ… Pod mutated

5. API Server: Validating Admission
   - PodSecurityPolicy: Checks security constraints
   - ResourceQuota: Validates resource limits
   - Custom Webhooks: External validation
   âœ… Pod validated

6. API Server: Schema Validation
   - Validates YAML structure
   - Checks required fields
   - Validates field types
   âœ… Valid

7. API Server: Persist to etcd
   - Writes pod object to etcd
   - etcd confirms write
   âœ… Persisted

8. API Server: Return Response
   - Returns pod object with metadata
   - Includes: UID, creation timestamp, resource version
   âœ… Success (201 Created)

9. Watchers Notified
   - Scheduler watching for unscheduled pods
   - Controllers watching for pod events
   - kubectl watching for pod status
   âœ… All notified via watch streams</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">API Server Features:</h4>
                <ul style="line-height: 2;">
                    <li><strong>RESTful API:</strong> Standard HTTP verbs (GET, POST, PUT, DELETE, PATCH)</li>
                    <li><strong>Watch API:</strong> Long-polling for real-time updates</li>
                    <li><strong>Versioning:</strong> Multiple API versions (v1, v1beta1, v1alpha1)</li>
                    <li><strong>API Groups:</strong> Organized by functionality (apps, batch, networking)</li>
                    <li><strong>Custom Resources:</strong> Extend API with CRDs</li>
                    <li><strong>Aggregation Layer:</strong> Extend API with custom API servers</li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">API Server Ports:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>6443  - Secure API port (HTTPS) - Main API endpoint
8080  - Insecure API port (HTTP) - Deprecated, disabled by default
10250 - kubelet API port
10251 - kube-scheduler health check
10252 - kube-controller-manager health check</code></pre>

                <div style="background: #1c4532; color: #9ae6b4; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>ğŸ’¡ Pro Tip:</strong> The API Server is stateless! You can run multiple instances behind a load balancer for high availability. All state is stored in etcd.
                </div>

                <div style="background: #742a2a; color: #fed7d7; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>âš ï¸ Security Note:</strong> The API Server is the attack surface of your cluster. Always:
                    <ul style="margin-top: 10px;">
                        <li>Use TLS for all connections</li>
                        <li>Enable RBAC</li>
                        <li>Audit logging</li>
                        <li>Restrict network access</li>
                        <li>Keep it updated</li>
                    </ul>
                </div>
            </div>

            <h3 style="color: #667eea;">2. etcd - The Cluster's Brain (Database)</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p style="font-size: 1.1rem; line-height: 1.8;"><strong>Role:</strong> etcd is a distributed, reliable key-value store that stores all cluster data. It's the single source of truth for your entire Kubernetes cluster.</p>
                
                <p><strong>Analogy:</strong> Like a library that keeps records of everything in the city - if the library burns down, the city loses all its records!</p>
                
                <h4 style="color: #90cdf4; margin-top: 20px;">What etcd Stores:</h4>
                <ul style="line-height: 2;">
                    <li><strong>Cluster Configuration:</strong> API server config, feature gates</li>
                    <li><strong>Resource Definitions:</strong> All Kubernetes objects (pods, services, deployments, etc.)</li>
                    <li><strong>Current State:</strong> What's actually running in the cluster</li>
                    <li><strong>Desired State:</strong> What should be running</li>
                    <li><strong>Secrets:</strong> Encrypted sensitive data</li>
                    <li><strong>ConfigMaps:</strong> Application configuration</li>
                    <li><strong>Node Information:</strong> Node status, capacity, conditions</li>
                    <li><strong>Network Policies:</strong> Security rules</li>
                    <li><strong>RBAC Policies:</strong> Access control rules</li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">etcd Architecture:</h4>
                <div style="background: #2d3748; color: #e2e8f0; padding: 20px; border-radius: 8px; margin-top: 15px;">
                    <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              etcd Cluster (High Availability)            â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  etcd Node 1 â”‚  â”‚  etcd Node 2 â”‚  â”‚  etcd Node 3 â”‚ â”‚
â”‚  â”‚   (Leader)   â”‚  â”‚  (Follower)  â”‚  â”‚  (Follower)  â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚  Port: 2379  â”‚  â”‚  Port: 2379  â”‚  â”‚  Port: 2379  â”‚ â”‚
â”‚  â”‚  (Client)    â”‚  â”‚  (Client)    â”‚  â”‚  (Client)    â”‚ â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚ â”‚
â”‚  â”‚  Port: 2380  â”‚  â”‚  Port: 2380  â”‚  â”‚  Port: 2380  â”‚ â”‚
â”‚  â”‚  (Peer)      â”‚  â”‚  (Peer)      â”‚  â”‚  (Peer)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                 â”‚                  â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                           â”‚                            â”‚
â”‚                  Raft Consensus Protocol               â”‚
â”‚              (Leader Election & Replication)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ (Only API Server talks to etcd)
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  API Server  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">Key Characteristics:</h4>
                
                <p><strong>1. Distributed & Consistent (Raft Consensus)</strong></p>
                <ul style="line-height: 2;">
                    <li>Uses Raft algorithm for consensus</li>
                    <li>Leader election: One leader, rest are followers</li>
                    <li>All writes go through leader</li>
                    <li>Leader replicates to followers</li>
                    <li>Requires quorum (majority) for writes</li>
                </ul>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Quorum calculation:
3 nodes: Need 2 for quorum (can tolerate 1 failure)
5 nodes: Need 3 for quorum (can tolerate 2 failures)
7 nodes: Need 4 for quorum (can tolerate 3 failures)

# Recommended: Always use odd numbers (3, 5, 7)
# Why? 4 nodes = same fault tolerance as 3 nodes (both need 3 for quorum)</code></pre>

                <p><strong>2. Strongly Consistent</strong></p>
                <ul style="line-height: 2;">
                    <li>Linearizable reads and writes</li>
                    <li>All clients see the same data at the same time</li>
                    <li>No eventual consistency - always consistent</li>
                </ul>

                <p><strong>3. Watch Mechanism</strong></p>
                <ul style="line-height: 2;">
                    <li>Clients can watch for changes to keys</li>
                    <li>Get notified immediately when data changes</li>
                    <li>This is how Kubernetes components stay in sync</li>
                </ul>

                <p><strong>4. Key-Value Store</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Example etcd keys (hierarchical structure):
/registry/pods/default/nginx-pod
/registry/services/default/nginx-service
/registry/deployments/default/nginx-deployment
/registry/secrets/default/db-password
/registry/configmaps/default/app-config
/registry/nodes/node-1
/registry/namespaces/default

# Each key stores JSON representation of the object</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">etcd Performance Characteristics:</h4>
                <ul style="line-height: 2;">
                    <li><strong>Read Performance:</strong> ~10,000 reads/sec per node</li>
                    <li><strong>Write Performance:</strong> ~1,000 writes/sec (limited by consensus)</li>
                    <li><strong>Latency:</strong> <10ms for writes in same datacenter</li>
                    <li><strong>Size Limit:</strong> Default 2GB (can be increased to 8GB)</li>
                    <li><strong>Key Size:</strong> Max 1.5 MB per key</li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">etcd Operations:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Check etcd health
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  endpoint health

# List all keys
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  get / --prefix --keys-only

# Get specific key
ETCDCTL_API=3 etcdctl get /registry/pods/default/nginx-pod

# Backup etcd (CRITICAL!)
ETCDCTL_API=3 etcdctl snapshot save backup.db

# Restore etcd from backup
ETCDCTL_API=3 etcdctl snapshot restore backup.db</code></pre>

                <div style="background: #742a2a; color: #fed7d7; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>âš ï¸ CRITICAL - etcd is the Most Important Component:</strong>
                    <ul style="margin-top: 10px; line-height: 2;">
                        <li><strong>If etcd goes down:</strong> Cluster is in read-only mode (can't create/update/delete)</li>
                        <li><strong>If etcd data is lost:</strong> Entire cluster state is lost (catastrophic!)</li>
                        <li><strong>If etcd is corrupted:</strong> Cluster may become unstable</li>
                    </ul>
                </div>

                <div style="background: #1c4532; color: #9ae6b4; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>âœ… etcd Best Practices:</strong>
                    <ul style="margin-top: 10px; line-height: 2;">
                        <li><strong>Backup regularly:</strong> Automated daily backups minimum</li>
                        <li><strong>Use SSD storage:</strong> etcd is I/O intensive</li>
                        <li><strong>Separate etcd nodes:</strong> Don't run on same nodes as workloads</li>
                        <li><strong>Monitor performance:</strong> Watch latency and disk I/O</li>
                        <li><strong>Use 3 or 5 nodes:</strong> For high availability</li>
                        <li><strong>Low latency network:</strong> <10ms between etcd nodes</li>
                        <li><strong>Encrypt at rest:</strong> Enable encryption for secrets</li>
                        <li><strong>Limit API Server connections:</strong> Prevent etcd overload</li>
                    </ul>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">etcd vs Other Databases:</h4>
                <table style="width: 100%; border-collapse: collapse; margin-top: 15px;">
                    <thead>
                        <tr style="background: #667eea; color: white;">
                            <th style="padding: 15px; text-align: left;">Feature</th>
                            <th style="padding: 15px; text-align: left;">etcd</th>
                            <th style="padding: 15px; text-align: left;">Redis</th>
                            <th style="padding: 15px; text-align: left;">Consul</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 15px;">Consistency</td>
                            <td style="padding: 15px;">Strong (Raft)</td>
                            <td style="padding: 15px;">Eventual</td>
                            <td style="padding: 15px;">Strong (Raft)</td>
                        </tr>
                        <tr style="background: rgba(255,255,255,0.02); border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 15px;">Watch API</td>
                            <td style="padding: 15px;">Yes</td>
                            <td style="padding: 15px;">Pub/Sub</td>
                            <td style="padding: 15px;">Yes</td>
                        </tr>
                        <tr style="border-bottom: 1px solid rgba(255,255,255,0.1);">
                            <td style="padding: 15px;">Use Case</td>
                            <td style="padding: 15px;">Config/Coordination</td>
                            <td style="padding: 15px;">Cache/Queue</td>
                            <td style="padding: 15px;">Service Discovery</td>
                        </tr>
                        <tr style="background: rgba(255,255,255,0.02);">
                            <td style="padding: 15px;">K8s Default</td>
                            <td style="padding: 15px;">âœ… Yes</td>
                            <td style="padding: 15px;">âŒ No</td>
                            <td style="padding: 15px;">âŒ No</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3 style="color: #667eea;">3. Scheduler (kube-scheduler) - The Matchmaker</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p style="font-size: 1.1rem; line-height: 1.8;"><strong>Role:</strong> The Scheduler watches for newly created pods that have no node assigned and selects the best node for them to run on based on resource requirements, constraints, and policies.</p>
                
                <p><strong>Analogy:</strong> Like a hotel manager assigning guests to rooms based on their needs, preferences, and room availability.</p>
                
                <h4 style="color: #90cdf4; margin-top: 20px;">Scheduling Algorithm - Two-Phase Process:</h4>
                
                <div style="background: #2d3748; color: #e2e8f0; padding: 20px; border-radius: 8px; margin-top: 15px;">
                    <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto; line-height: 1.6;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Scheduler Decision Process                      â”‚
â”‚                                                              â”‚
â”‚  1. Watch API Server for unscheduled pods                   â”‚
â”‚     â†“                                                        â”‚
â”‚  2. FILTERING PHASE (Predicates)                            â”‚
â”‚     Find all nodes that CAN run the pod                     â”‚
â”‚     â†“                                                        â”‚
â”‚     Filters Applied:                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ â€¢ PodFitsResources                          â”‚        â”‚
â”‚     â”‚   - Enough CPU?                             â”‚        â”‚
â”‚     â”‚   - Enough Memory?                          â”‚        â”‚
â”‚     â”‚   - Enough Ephemeral Storage?               â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ PodFitsHost                               â”‚        â”‚
â”‚     â”‚   - Matches nodeName if specified?          â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ PodFitsHostPorts                          â”‚        â”‚
â”‚     â”‚   - Required ports available?               â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ PodMatchNodeSelector                      â”‚        â”‚
â”‚     â”‚   - Matches node labels?                    â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ CheckNodeTaints                           â”‚        â”‚
â”‚     â”‚   - Pod tolerates node taints?              â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ CheckVolumeBinding                        â”‚        â”‚
â”‚     â”‚   - Can volumes be bound?                   â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ CheckNodeAffinity                         â”‚        â”‚
â”‚     â”‚   - Matches affinity rules?                 â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ CheckPodAffinity/AntiAffinity             â”‚        â”‚
â”‚     â”‚   - Satisfies pod affinity rules?           â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚     Result: List of feasible nodes                          â”‚
â”‚     â†“                                                        â”‚
â”‚  3. SCORING PHASE (Priorities)                              â”‚
â”‚     Rank feasible nodes (0-100 score)                       â”‚
â”‚     â†“                                                        â”‚
â”‚     Scoring Functions:                                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ â€¢ LeastRequestedPriority                    â”‚        â”‚
â”‚     â”‚   - Prefer nodes with more available        â”‚        â”‚
â”‚     â”‚     resources (better utilization)          â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ BalancedResourceAllocation                â”‚        â”‚
â”‚     â”‚   - Balance CPU and memory usage            â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ SelectorSpreadPriority                    â”‚        â”‚
â”‚     â”‚   - Spread pods across nodes                â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ NodeAffinityPriority                      â”‚        â”‚
â”‚     â”‚   - Prefer nodes matching affinity          â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ TaintTolerationPriority                   â”‚        â”‚
â”‚     â”‚   - Prefer nodes with fewer taints          â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ InterPodAffinityPriority                  â”‚        â”‚
â”‚     â”‚   - Prefer nodes satisfying pod affinity    â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ ImageLocalityPriority                     â”‚        â”‚
â”‚     â”‚   - Prefer nodes with image already cached  â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚     Result: Nodes ranked by score                           â”‚
â”‚     â†“                                                        â”‚
â”‚  4. BINDING PHASE                                            â”‚
â”‚     Assign pod to highest-scoring node                      â”‚
â”‚     â†“                                                        â”‚
â”‚     â€¢ Update pod.spec.nodeName in API Server                â”‚
â”‚     â€¢ API Server persists to etcd                           â”‚
â”‚     â€¢ kubelet on selected node picks up the pod             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">Detailed Scheduling Example:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Pod Requirements:
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  containers:
  - name: app
    image: myapp:1.0
    resources:
      requests:
        cpu: 2
        memory: 4Gi
  nodeSelector:
    disktype: ssd

# Cluster State:
Node 1: 
  - CPU: 4 cores (1 core used, 3 available)
  - Memory: 8Gi (2Gi used, 6Gi available)
  - Labels: disktype=hdd
  - Status: Ready

Node 2:
  - CPU: 8 cores (4 cores used, 4 available)
  - Memory: 16Gi (8Gi used, 8Gi available)
  - Labels: disktype=ssd
  - Status: Ready

Node 3:
  - CPU: 16 cores (2 cores used, 14 available)
  - Memory: 32Gi (4Gi used, 28Gi available)
  - Labels: disktype=ssd
  - Status: Ready

# Scheduler Decision Process:

FILTERING PHASE:
-----------------
Node 1:
  âœ… PodFitsResources: 3 CPU available >= 2 CPU needed
  âœ… PodFitsResources: 6Gi available >= 4Gi needed
  âŒ PodMatchNodeSelector: disktype=hdd != disktype=ssd
  Result: FILTERED OUT

Node 2:
  âœ… PodFitsResources: 4 CPU available >= 2 CPU needed
  âœ… PodFitsResources: 8Gi available >= 4Gi needed
  âœ… PodMatchNodeSelector: disktype=ssd matches
  Result: FEASIBLE

Node 3:
  âœ… PodFitsResources: 14 CPU available >= 2 CPU needed
  âœ… PodFitsResources: 28Gi available >= 4Gi needed
  âœ… PodMatchNodeSelector: disktype=ssd matches
  Result: FEASIBLE

Feasible Nodes: [Node 2, Node 3]

SCORING PHASE:
--------------
Node 2:
  LeastRequestedPriority:
    CPU: (4 - 2) / 4 = 50% available â†’ Score: 50
    Memory: (8 - 4) / 8 = 50% available â†’ Score: 50
    Average: 50
  
  BalancedResourceAllocation:
    CPU usage after: (4 + 2) / 8 = 75%
    Memory usage after: (8 + 4) / 16 = 75%
    Difference: 0% â†’ Score: 100 (perfectly balanced)
  
  Total Score: (50 + 100) / 2 = 75

Node 3:
  LeastRequestedPriority:
    CPU: (14 - 2) / 16 = 75% available â†’ Score: 75
    Memory: (28 - 4) / 32 = 75% available â†’ Score: 75
    Average: 75
  
  BalancedResourceAllocation:
    CPU usage after: (2 + 2) / 16 = 25%
    Memory usage after: (4 + 4) / 32 = 25%
    Difference: 0% â†’ Score: 100 (perfectly balanced)
  
  Total Score: (75 + 100) / 2 = 87.5

BINDING PHASE:
--------------
Winner: Node 3 (Score: 87.5)
Action: Bind pod "my-app" to Node 3
Result: pod.spec.nodeName = "node-3"</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Scheduling Constraints:</h4>
                
                <p><strong>1. Node Selectors (Simple)</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>spec:
  nodeSelector:
    disktype: ssd
    region: us-west
# Pod will ONLY run on nodes with BOTH labels</code></pre>

                <p><strong>2. Node Affinity (Advanced)</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values: [ssd, nvme]
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80
        preference:
          matchExpressions:
          - key: region
            operator: In
            values: [us-west]</code></pre>

                <p><strong>3. Taints and Tolerations</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Taint on node (repels pods)
kubectl taint nodes node1 key=value:NoSchedule

# Toleration on pod (allows scheduling despite taint)
spec:
  tolerations:
  - key: "key"
    operator: "Equal"
    value: "value"
    effect: "NoSchedule"</code></pre>

                <p><strong>4. Pod Affinity/Anti-Affinity</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Run near cache pods (affinity)
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values: [cache]
        topologyKey: kubernetes.io/hostname

# Don't run on same node as other replicas (anti-affinity)
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values: [myapp]
        topologyKey: kubernetes.io/hostname</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Scheduler Performance:</h4>
                <ul style="line-height: 2;">
                    <li><strong>Throughput:</strong> Can schedule 100+ pods per second</li>
                    <li><strong>Latency:</strong> Typically <100ms per pod</li>
                    <li><strong>Scalability:</strong> Handles clusters with 5000+ nodes</li>
                    <li><strong>Extensibility:</strong> Custom schedulers and scheduler extenders supported</li>
                </ul>

                <div style="background: #1c4532; color: #9ae6b4; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>ğŸ’¡ Pro Tips:</strong>
                    <ul style="margin-top: 10px; line-height: 2;">
                        <li>Use node affinity for flexible node selection</li>
                        <li>Use pod anti-affinity for high availability (spread replicas)</li>
                        <li>Use taints for dedicated nodes (GPU, high-memory)</li>
                        <li>Monitor scheduler queue depth and latency</li>
                        <li>Consider custom schedulers for special workloads</li>
                    </ul>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">Troubleshooting Scheduling Issues:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Check why pod is not scheduled
kubectl describe pod <pod-name>

# Common issues:
# 1. Insufficient resources
Events:
  Warning  FailedScheduling  pod has unbound immediate PersistentVolumeClaims
  
# 2. No nodes match selector
Events:
  Warning  FailedScheduling  0/3 nodes are available: 3 node(s) didn't match node selector

# 3. Taints not tolerated
Events:
  Warning  FailedScheduling  0/3 nodes are available: 3 node(s) had taint {key: value}, that the pod didn't tolerate

# View scheduler logs
kubectl logs -n kube-system kube-scheduler-<node-name></code></pre>
            </div>

            <h3 style="color: #667eea;">4. Controller Manager (kube-controller-manager) - The Autopilot</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p style="font-size: 1.1rem; line-height: 1.8;"><strong>Role:</strong> The Controller Manager runs multiple controllers that continuously watch the cluster state and make changes to move the current state toward the desired state. It's the autopilot that keeps everything running smoothly.</p>
                
                <p><strong>Analogy:</strong> Like building maintenance staff who constantly check and fix things - HVAC controller maintains temperature, security controller monitors access, cleaning controller maintains cleanliness.</p>
                
                <h4 style="color: #90cdf4; margin-top: 20px;">Controller Pattern - The Core Concept:</h4>
                <div style="background: #2d3748; color: #e2e8f0; padding: 20px; border-radius: 8px; margin-top: 15px;">
                    <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto; line-height: 1.6;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Controller Reconciliation Loop              â”‚
â”‚                                                          â”‚
â”‚  while true:                                            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚  1. OBSERVE                                  â”‚    â”‚
â”‚    â”‚     Watch API Server for changes             â”‚    â”‚
â”‚    â”‚     Get current state                        â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                   â”‚                                     â”‚
â”‚                   â–¼                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚  2. DIFF                                     â”‚    â”‚
â”‚    â”‚     Compare current state vs desired state   â”‚    â”‚
â”‚    â”‚     Identify differences                     â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                   â”‚                                     â”‚
â”‚                   â–¼                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚  3. ACT                                      â”‚    â”‚
â”‚    â”‚     Make changes to reconcile state          â”‚    â”‚
â”‚    â”‚     Create/Update/Delete resources           â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                   â”‚                                     â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                                 â”‚                       â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                   â”‚  Wait for next event or   â”‚        â”‚
â”‚                   â”‚  periodic sync (30s)      â”‚        â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example: ReplicaSet Controller
Desired: 3 replicas
Current: 2 replicas (1 crashed)
Diff: Need 1 more replica
Action: Create 1 new pod
Result: 3 replicas running âœ…</code></pre>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">Built-in Controllers (20+):</h4>
                
                <p><strong>1. Node Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Monitors node health and manages node lifecycle</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Assigns CIDR blocks to new nodes</li>
                            <li>Keeps node list up to date</li>
                            <li>Monitors node health (heartbeats every 10s)</li>
                            <li>Marks nodes as NotReady if no heartbeat for 40s</li>
                            <li>Evicts pods from NotReady nodes after 5 minutes</li>
                        </ul>
                    </li>
                </ul>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Node lifecycle:
Ready â†’ NotReady (40s no heartbeat) â†’ Evict pods (5 min) â†’ Delete node (optional)

# Node conditions monitored:
- Ready: Node is healthy and ready to accept pods
- MemoryPressure: Node is running out of memory
- DiskPressure: Node is running out of disk space
- PIDPressure: Too many processes running
- NetworkUnavailable: Network not configured correctly</code></pre>

                <p><strong>2. Replication Controller / ReplicaSet Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Ensures correct number of pod replicas are running</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates pods if count < desired</li>
                            <li>Deletes pods if count > desired</li>
                            <li>Replaces failed pods</li>
                            <li>Handles pod adoption (pods without owner)</li>
                        </ul>
                    </li>
                </ul>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Example: ReplicaSet with 3 replicas
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21

# Controller actions:
# - Watches for ReplicaSet changes
# - Counts pods matching selector (app=nginx)
# - If count != 3, creates or deletes pods
# - Continuously reconciles every 30s</code></pre>

                <p><strong>3. Deployment Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages Deployments and their ReplicaSets</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates ReplicaSets for new Deployments</li>
                            <li>Performs rolling updates</li>
                            <li>Handles rollbacks</li>
                            <li>Scales ReplicaSets</li>
                            <li>Pauses/resumes rollouts</li>
                        </ul>
                    </li>
                </ul>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Rolling update process:
1. User updates Deployment image: nginx:1.20 â†’ nginx:1.21
2. Deployment Controller creates new ReplicaSet (nginx:1.21)
3. Gradually scales up new RS, scales down old RS
4. Strategy: RollingUpdate (default)
   - maxSurge: 25% (max pods above desired during update)
   - maxUnavailable: 25% (max pods unavailable during update)

# Example with 4 replicas:
Old RS (nginx:1.20): 4 pods
New RS (nginx:1.21): 0 pods
â†“
Old RS: 3 pods, New RS: 1 pod (surge: 1)
â†“
Old RS: 2 pods, New RS: 2 pods
â†“
Old RS: 1 pod, New RS: 3 pods
â†“
Old RS: 0 pods, New RS: 4 pods âœ…</code></pre>

                <p><strong>4. StatefulSet Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages stateful applications</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates pods in order (0, 1, 2...)</li>
                            <li>Provides stable network identities</li>
                            <li>Manages persistent storage</li>
                            <li>Performs ordered, graceful scaling</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>5. DaemonSet Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Ensures a pod runs on all (or some) nodes</li>
                    <li><strong>Use Cases:</strong> Log collectors, monitoring agents, network plugins</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates pod on new nodes</li>
                            <li>Deletes pod when node is removed</li>
                            <li>Respects node selectors and taints</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>6. Job Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages batch jobs</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates pods to run to completion</li>
                            <li>Tracks successful completions</li>
                            <li>Retries failed pods</li>
                            <li>Cleans up completed jobs (optional)</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>7. CronJob Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages scheduled jobs</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates Jobs on schedule (cron format)</li>
                            <li>Manages job history</li>
                            <li>Handles missed schedules</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>8. Service Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages Services</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates cloud load balancers for LoadBalancer services</li>
                            <li>Allocates cluster IPs</li>
                            <li>Updates endpoints</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>9. Endpoints Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Populates Endpoints objects</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Watches Services and Pods</li>
                            <li>Creates Endpoints linking Services to Pods</li>
                            <li>Updates Endpoints when pods change</li>
                        </ul>
                    </li>
                </ul>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Service selects pods with label app=nginx
# Endpoints Controller finds matching pods and creates:
apiVersion: v1
kind: Endpoints
metadata:
  name: nginx-service
subsets:
- addresses:
  - ip: 10.244.1.5  # Pod 1 IP
  - ip: 10.244.2.3  # Pod 2 IP
  - ip: 10.244.3.7  # Pod 3 IP
  ports:
  - port: 80</code></pre>

                <p><strong>10. Namespace Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages namespace lifecycle</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Deletes all resources in namespace when namespace is deleted</li>
                            <li>Prevents deletion of system namespaces</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>11. ServiceAccount Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages ServiceAccounts</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Creates default ServiceAccount in new namespaces</li>
                            <li>Creates tokens for ServiceAccounts</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>12. PersistentVolume Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Manages PV and PVC binding</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Binds PVCs to PVs</li>
                            <li>Provisions dynamic volumes</li>
                            <li>Handles volume lifecycle</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>13. ResourceQuota Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Enforces resource quotas</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Tracks resource usage per namespace</li>
                            <li>Rejects requests exceeding quota</li>
                        </ul>
                    </li>
                </ul>

                <p><strong>14. Garbage Collector Controller</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>Responsibility:</strong> Cleans up orphaned resources</li>
                    <li><strong>Actions:</strong>
                        <ul>
                            <li>Deletes dependent objects when owner is deleted</li>
                            <li>Handles cascading deletion</li>
                        </ul>
                    </li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">Controller Manager Configuration:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Key flags:
--controllers=*                    # Which controllers to run (* = all)
--node-monitor-period=5s          # How often to check node health
--node-monitor-grace-period=40s   # Grace period before marking NotReady
--pod-eviction-timeout=5m         # Time before evicting pods from NotReady node
--concurrent-deployment-syncs=5   # Concurrent deployment reconciliations
--leader-elect=true               # Enable leader election for HA</code></pre>

                <div style="background: #1c4532; color: #9ae6b4; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>ğŸ’¡ Understanding Controllers:</strong>
                    <ul style="margin-top: 10px; line-height: 2;">
                        <li>Controllers are the "brains" that make Kubernetes self-healing</li>
                        <li>Each controller is responsible for one resource type</li>
                        <li>Controllers run in parallel and independently</li>
                        <li>You can write custom controllers for custom resources (CRDs)</li>
                        <li>Controllers use optimistic concurrency (resource versions)</li>
                    </ul>
                </div>
            </div>

            <h3 style="color: #667eea;">5. Cloud Controller Manager (Optional)</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p><strong>Role:</strong> Integrates with cloud provider APIs (AWS, Azure, GCP).</p>
                
                <p><strong>What it manages:</strong></p>
                <ul>
                    <li>Load balancers (creates cloud LBs for LoadBalancer services)</li>
                    <li>Nodes (checks if deleted nodes exist in cloud)</li>
                    <li>Routes (sets up network routes in cloud)</li>
                    <li>Volumes (creates/attaches cloud storage)</li>
                </ul>
            </div>

            <h2>âš™ï¸ Worker Node Components</h2>

            <p>Worker Nodes are where your applications actually run. Each node has three main components:</p>

            <h3 style="color: #667eea;">1. kubelet - The Node Agent</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p style="font-size: 1.1rem; line-height: 1.8;"><strong>Role:</strong> The kubelet is the primary node agent that runs on each worker node. It's responsible for managing pods and containers on its node, ensuring they're running and healthy.</p>
                
                <p><strong>Analogy:</strong> Like a building superintendent who manages their building - ensures apartments (pods) are occupied, maintained, and functioning properly.</p>
                
                <h4 style="color: #90cdf4; margin-top: 20px;">Core Responsibilities:</h4>
                <ul style="line-height: 2;">
                    <li><strong>Node Registration:</strong> Registers the node with API Server</li>
                    <li><strong>Pod Management:</strong> Watches API Server for pods assigned to its node</li>
                    <li><strong>Container Lifecycle:</strong> Starts, stops, and restarts containers</li>
                    <li><strong>Health Monitoring:</strong> Runs liveness, readiness, and startup probes</li>
                    <li><strong>Resource Reporting:</strong> Reports node and pod status to API Server</li>
                    <li><strong>Volume Management:</strong> Mounts volumes for pods</li>
                    <li><strong>Image Management:</strong> Pulls container images</li>
                    <li><strong>Pod Eviction:</strong> Evicts pods when node resources are low</li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">kubelet Workflow:</h4>
                <div style="background: #2d3748; color: #e2e8f0; padding: 20px; border-radius: 8px; margin-top: 15px;">
                    <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto; line-height: 1.6;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              kubelet Pod Lifecycle Management                â”‚
â”‚                                                              â”‚
â”‚  1. Watch API Server                                        â”‚
â”‚     - Long-polling watch on /api/v1/pods                    â”‚
â”‚     - Filter: pods where spec.nodeName == this node         â”‚
â”‚     â†“                                                        â”‚
â”‚  2. Receive Pod Spec                                        â”‚
â”‚     - New pod assigned to this node                         â”‚
â”‚     - Pod spec includes: containers, volumes, etc.          â”‚
â”‚     â†“                                                        â”‚
â”‚  3. Sync Pod                                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ a. Create Pod Sandbox                       â”‚        â”‚
â”‚     â”‚    - Set up network namespace               â”‚        â”‚
â”‚     â”‚    - Allocate IP address                    â”‚        â”‚
â”‚     â”‚    - Set up pause container                 â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ b. Pull Images                              â”‚        â”‚
â”‚     â”‚    - Check if image exists locally          â”‚        â”‚
â”‚     â”‚    - Pull from registry if needed           â”‚        â”‚
â”‚     â”‚    - Verify image integrity                 â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ c. Mount Volumes                            â”‚        â”‚
â”‚     â”‚    - Create volume directories              â”‚        â”‚
â”‚     â”‚    - Mount ConfigMaps/Secrets               â”‚        â”‚
â”‚     â”‚    - Attach persistent volumes              â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ d. Start Init Containers (if any)           â”‚        â”‚
â”‚     â”‚    - Run sequentially                       â”‚        â”‚
â”‚     â”‚    - Wait for each to complete              â”‚        â”‚
â”‚     â”‚    - Fail pod if init container fails       â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ e. Start Main Containers                    â”‚        â”‚
â”‚     â”‚    - Start all containers in parallel       â”‚        â”‚
â”‚     â”‚    - Set up environment variables           â”‚        â”‚
â”‚     â”‚    - Apply resource limits                  â”‚        â”‚
â”‚     â”‚    - Apply security context                 â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚  4. Monitor Container Health                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ â€¢ Liveness Probe (is container alive?)     â”‚        â”‚
â”‚     â”‚   - HTTP GET, TCP Socket, or Exec          â”‚        â”‚
â”‚     â”‚   - If fails: restart container            â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ Readiness Probe (ready for traffic?)     â”‚        â”‚
â”‚     â”‚   - HTTP GET, TCP Socket, or Exec          â”‚        â”‚
â”‚     â”‚   - If fails: remove from endpoints        â”‚        â”‚
â”‚     â”‚                                             â”‚        â”‚
â”‚     â”‚ â€¢ Startup Probe (has it started?)          â”‚        â”‚
â”‚     â”‚   - For slow-starting containers           â”‚        â”‚
â”‚     â”‚   - Disables liveness until passes         â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚  5. Report Status to API Server                             â”‚
â”‚     - Pod phase (Pending, Running, Succeeded, Failed)       â”‚
â”‚     - Container states (Waiting, Running, Terminated)       â”‚
â”‚     - Resource usage (CPU, memory)                          â”‚
â”‚     - Events (pulled image, started container, etc.)        â”‚
â”‚     â†“                                                        â”‚
â”‚  6. Continuous Reconciliation                               â”‚
â”‚     - Every 10 seconds: sync pod state                      â”‚
â”‚     - Every 10 seconds: run health probes                   â”‚
â”‚     - Every 10 seconds: report status                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">kubelet Communication:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># kubelet talks to:
1. API Server (port 6443)
   - Watch for pod assignments
   - Report node/pod status
   - Get secrets/configmaps

2. Container Runtime (via CRI)
   - Start/stop containers
   - List containers
   - Get container stats

3. CNI Plugin (via CNI)
   - Set up pod networking
   - Allocate IP addresses

4. CSI Plugin (via CSI)
   - Mount volumes
   - Unmount volumes

# kubelet exposes:
- Port 10250: kubelet API (authenticated)
- Port 10255: Read-only API (deprecated)
- Port 10248: Health check endpoint</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Pod Lifecycle Phases:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Pod goes through these phases:

1. Pending
   - Pod accepted by cluster
   - Waiting for scheduling or image pull
   
2. Running
   - Pod bound to node
   - At least one container is running
   
3. Succeeded
   - All containers terminated successfully
   - Won't be restarted
   
4. Failed
   - All containers terminated
   - At least one failed (non-zero exit)
   
5. Unknown
   - Can't determine pod state
   - Usually communication error with node

# Container states within pod:
- Waiting: Not running yet (pulling image, waiting for init)
- Running: Executing normally
- Terminated: Finished execution or was killed</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Health Probes in Detail:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Liveness Probe (restart if fails)
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 30  # Wait before first probe
  periodSeconds: 10        # Probe every 10s
  timeoutSeconds: 5        # Timeout after 5s
  successThreshold: 1      # 1 success = healthy
  failureThreshold: 3      # 3 failures = restart

# Readiness Probe (remove from service if fails)
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
  
# Startup Probe (for slow-starting apps)
startupProbe:
  httpGet:
    path: /startup
    port: 8080
  failureThreshold: 30     # 30 * 10s = 5 minutes to start
  periodSeconds: 10

# Probe types:
1. HTTP GET: Success if 200-399 response
2. TCP Socket: Success if port is open
3. Exec: Success if command exits with 0</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Resource Management:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># kubelet enforces resource limits using cgroups

# Pod with resource requests/limits:
resources:
  requests:
    cpu: 500m      # 0.5 CPU cores (guaranteed)
    memory: 512Mi  # 512 MiB (guaranteed)
  limits:
    cpu: 1000m     # 1 CPU core (max)
    memory: 1Gi    # 1 GiB (max, killed if exceeded)

# kubelet actions:
1. Reserves requested resources (scheduling)
2. Enforces limits via cgroups
3. Evicts pods if node resources are low
4. Prioritizes eviction by QoS class:
   - BestEffort (no requests/limits) â†’ evicted first
   - Burstable (requests < limits) â†’ evicted second
   - Guaranteed (requests = limits) â†’ evicted last</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Pod Eviction:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># kubelet evicts pods when node resources are low

# Eviction signals:
- memory.available < 100Mi
- nodefs.available < 10% (root filesystem)
- nodefs.inodesFree < 5%
- imagefs.available < 15% (image filesystem)

# Eviction process:
1. kubelet detects resource pressure
2. Marks node with condition (MemoryPressure, DiskPressure)
3. Stops accepting new pods
4. Evicts pods based on priority:
   - BestEffort pods first
   - Burstable pods exceeding requests
   - Guaranteed pods (only if critical)
5. Sends SIGTERM to containers
6. Waits 30s (grace period)
7. Sends SIGKILL if still running</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">kubelet Configuration:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Key kubelet flags:
--kubeconfig=/etc/kubernetes/kubelet.conf
--config=/var/lib/kubelet/config.yaml
--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock
--pod-infra-container-image=k8s.gcr.io/pause:3.9
--max-pods=110                    # Max pods per node
--node-status-update-frequency=10s
--image-pull-progress-deadline=1m
--eviction-hard=memory.available<100Mi
--eviction-soft=memory.available<300Mi
--eviction-soft-grace-period=memory.available=1m30s</code></pre>

                <div style="background: #1c4532; color: #9ae6b4; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>ğŸ’¡ kubelet Best Practices:</strong>
                    <ul style="margin-top: 10px; line-height: 2;">
                        <li>Always set resource requests and limits</li>
                        <li>Use readiness probes to prevent traffic to unhealthy pods</li>
                        <li>Use liveness probes to restart crashed containers</li>
                        <li>Use startup probes for slow-starting applications</li>
                        <li>Monitor kubelet logs for errors</li>
                        <li>Keep kubelet version in sync with API Server</li>
                        <li>Use SSD for kubelet working directory</li>
                    </ul>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">Troubleshooting kubelet:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Check kubelet status
systemctl status kubelet

# View kubelet logs
journalctl -u kubelet -f

# Check kubelet configuration
kubectl get --raw /api/v1/nodes/<node-name>/proxy/configz

# Common issues:
1. Node NotReady
   - Check kubelet is running
   - Check network connectivity to API Server
   - Check container runtime is running

2. Pods stuck in Pending
   - Check kubelet logs
   - Check if image can be pulled
   - Check resource availability

3. Pods being evicted
   - Check node resource usage
   - Check eviction thresholds
   - Add more resources or reduce pod requests</code></pre>
            </div>

            <h3 style="color: #667eea;">2. kube-proxy - The Network Traffic Controller</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p style="font-size: 1.1rem; line-height: 1.8;"><strong>Role:</strong> kube-proxy is a network proxy that runs on each node and maintains network rules. It implements the Kubernetes Service concept by enabling network communication to pods from inside or outside the cluster.</p>
                
                <p><strong>Analogy:</strong> Like a traffic cop directing traffic to the right destinations - when you ask for "nginx-service", kube-proxy knows which pods to send you to.</p>
                
                <h4 style="color: #90cdf4; margin-top: 20px;">What kube-proxy Does:</h4>
                <ul style="line-height: 2;">
                    <li><strong>Service Implementation:</strong> Makes Kubernetes Services work</li>
                    <li><strong>Load Balancing:</strong> Distributes traffic across pod replicas</li>
                    <li><strong>Network Rules:</strong> Maintains iptables/IPVS rules</li>
                    <li><strong>Service Discovery:</strong> Routes traffic to correct pods</li>
                    <li><strong>Health-Aware Routing:</strong> Only sends traffic to ready pods</li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">How Services Work:</h4>
                <div style="background: #2d3748; color: #e2e8f0; padding: 20px; border-radius: 8px; margin-top: 15px;">
                    <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto; line-height: 1.6;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Service to Pod Routing                          â”‚
â”‚                                                              â”‚
â”‚  1. Create Service                                          â”‚
â”‚     apiVersion: v1                                          â”‚
â”‚     kind: Service                                           â”‚
â”‚     metadata:                                               â”‚
â”‚       name: nginx-service                                   â”‚
â”‚     spec:                                                   â”‚
â”‚       selector:                                             â”‚
â”‚         app: nginx                                          â”‚
â”‚       ports:                                                â”‚
â”‚       - port: 80                                            â”‚
â”‚         targetPort: 8080                                    â”‚
â”‚     â†“                                                        â”‚
â”‚  2. API Server assigns ClusterIP                            â”‚
â”‚     Service IP: 10.96.0.10                                  â”‚
â”‚     â†“                                                        â”‚
â”‚  3. Endpoints Controller finds matching pods                â”‚
â”‚     Pod 1: 10.244.1.5:8080                                  â”‚
â”‚     Pod 2: 10.244.2.3:8080                                  â”‚
â”‚     Pod 3: 10.244.3.7:8080                                  â”‚
â”‚     â†“                                                        â”‚
â”‚  4. kube-proxy watches Service and Endpoints                â”‚
â”‚     â†“                                                        â”‚
â”‚  5. kube-proxy creates network rules                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚  Traffic to 10.96.0.10:80 â†’                 â”‚        â”‚
â”‚     â”‚    Load balance to:                         â”‚        â”‚
â”‚     â”‚    - 10.244.1.5:8080 (33%)                  â”‚        â”‚
â”‚     â”‚    - 10.244.2.3:8080 (33%)                  â”‚        â”‚
â”‚     â”‚    - 10.244.3.7:8080 (33%)                  â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚     â†“                                                        â”‚
â”‚  6. Client sends request to Service IP                      â”‚
â”‚     curl http://10.96.0.10:80                               â”‚
â”‚     â†“                                                        â”‚
â”‚  7. kube-proxy intercepts and forwards to pod               â”‚
â”‚     Request â†’ 10.244.2.3:8080 (random pod selected)         â”‚
â”‚     â†“                                                        â”‚
â”‚  8. Pod processes request and responds                      â”‚
â”‚     Response â†’ Client                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">kube-proxy Modes:</h4>
                
                <p><strong>1. iptables Mode (Default)</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>How it works:</strong> Uses Linux iptables rules for packet filtering and NAT</li>
                    <li><strong>Pros:</strong>
                        <ul>
                            <li>Mature and stable</li>
                            <li>No additional dependencies</li>
                            <li>Works on all Linux distributions</li>
                        </ul>
                    </li>
                    <li><strong>Cons:</strong>
                        <ul>
                            <li>Performance degrades with many services (O(n) complexity)</li>
                            <li>Random load balancing only</li>
                            <li>No connection tracking</li>
                        </ul>
                    </li>
                </ul>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Example iptables rules created by kube-proxy:

# KUBE-SERVICES chain (entry point)
-A KUBE-SERVICES -d 10.96.0.10/32 -p tcp -m tcp --dport 80 \
   -j KUBE-SVC-NGINX

# KUBE-SVC-NGINX chain (load balancing)
-A KUBE-SVC-NGINX -m statistic --mode random --probability 0.33 \
   -j KUBE-SEP-POD1
-A KUBE-SVC-NGINX -m statistic --mode random --probability 0.50 \
   -j KUBE-SEP-POD2
-A KUBE-SVC-NGINX -j KUBE-SEP-POD3

# KUBE-SEP-POD1 chain (DNAT to pod)
-A KUBE-SEP-POD1 -p tcp -m tcp \
   -j DNAT --to-destination 10.244.1.5:8080

# Similar rules for POD2 and POD3...</code></pre>

                <p><strong>2. IPVS Mode (Recommended for Large Clusters)</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>How it works:</strong> Uses Linux IPVS (IP Virtual Server) for load balancing</li>
                    <li><strong>Pros:</strong>
                        <ul>
                            <li>Better performance (O(1) complexity)</li>
                            <li>Multiple load balancing algorithms (rr, lc, dh, sh, etc.)</li>
                            <li>Connection tracking</li>
                            <li>Scales to 10,000+ services</li>
                        </ul>
                    </li>
                    <li><strong>Cons:</strong>
                        <ul>
                            <li>Requires IPVS kernel modules</li>
                            <li>More complex to debug</li>
                        </ul>
                    </li>
                </ul>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Enable IPVS mode:
kube-proxy --proxy-mode=ipvs

# Load balancing algorithms:
--ipvs-scheduler=rr    # Round Robin (default)
--ipvs-scheduler=lc    # Least Connection
--ipvs-scheduler=dh    # Destination Hashing
--ipvs-scheduler=sh    # Source Hashing
--ipvs-scheduler=sed   # Shortest Expected Delay
--ipvs-scheduler=nq    # Never Queue

# View IPVS rules:
ipvsadm -Ln

# Output:
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.96.0.10:80 rr
  -> 10.244.1.5:8080              Masq    1      0          0
  -> 10.244.2.3:8080              Masq    1      0          0
  -> 10.244.3.7:8080              Masq    1      0          0</code></pre>

                <p><strong>3. userspace Mode (Legacy, Deprecated)</strong></p>
                <ul style="line-height: 2;">
                    <li><strong>How it works:</strong> kube-proxy acts as a proxy server</li>
                    <li><strong>Status:</strong> Deprecated, not recommended</li>
                    <li><strong>Issue:</strong> All traffic goes through userspace (slow)</li>
                </ul>

                <h4 style="color: #90cdf4; margin-top: 20px;">Service Types and kube-proxy:</h4>
                
                <p><strong>1. ClusterIP (Default)</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: ClusterIP  # Internal cluster IP
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 8080

# kube-proxy creates rules for ClusterIP
# Accessible only within cluster</code></pre>

                <p><strong>2. NodePort</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 8080
    nodePort: 30080  # Exposed on all nodes

# kube-proxy creates rules:
# 1. ClusterIP rules (10.96.0.10:80)
# 2. NodePort rules (NodeIP:30080)
# Accessible from outside: http://<any-node-ip>:30080</code></pre>

                <p><strong>3. LoadBalancer</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 8080

# kube-proxy creates rules:
# 1. ClusterIP rules
# 2. NodePort rules
# 3. Cloud provider creates external load balancer
# Accessible from internet: http://<external-lb-ip>:80</code></pre>

                <p><strong>4. ExternalName</strong></p>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>apiVersion: v1
kind: Service
metadata:
  name: external-db
spec:
  type: ExternalName
  externalName: database.example.com

# kube-proxy creates DNS CNAME record
# No load balancing, just DNS resolution</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Session Affinity:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Stick client to same pod (session affinity)
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  sessionAffinity: ClientIP  # Default: None
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800  # 3 hours

# kube-proxy ensures same client IP goes to same pod</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">kube-proxy Configuration:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Key kube-proxy flags:
--proxy-mode=iptables          # or ipvs
--cluster-cidr=10.244.0.0/16   # Pod CIDR
--iptables-sync-period=30s     # How often to sync rules
--ipvs-sync-period=30s
--ipvs-scheduler=rr            # IPVS algorithm
--masquerade-all=false         # SNAT all traffic
--cleanup-iptables=true        # Clean up on exit</code></pre>

                <h4 style="color: #90cdf4; margin-top: 20px;">Network Flow Example:</h4>
                <div style="background: #2d3748; color: #e2e8f0; padding: 20px; border-radius: 8px; margin-top: 15px;">
                    <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Pod-to-Service Communication Flow                    â”‚
â”‚                                                              â”‚
â”‚  Client Pod (10.244.1.10)                                   â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”‚ curl http://nginx-service:80                          â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  DNS Resolution                                             â”‚
â”‚     nginx-service â†’ 10.96.0.10 (ClusterIP)                  â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  Packet: src=10.244.1.10, dst=10.96.0.10:80                â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  kube-proxy iptables/IPVS rules                             â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”œâ”€ Match: dst=10.96.0.10:80                             â”‚
â”‚     â”œâ”€ Load balance: Select pod (round-robin)               â”‚
â”‚     â”œâ”€ DNAT: dst=10.96.0.10:80 â†’ 10.244.2.5:8080           â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  Packet: src=10.244.1.10, dst=10.244.2.5:8080              â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  Target Pod (10.244.2.5)                                    â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”‚ Process request                                       â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  Response: src=10.244.2.5:8080, dst=10.244.1.10            â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  kube-proxy reverse NAT                                     â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”œâ”€ SNAT: src=10.244.2.5:8080 â†’ 10.96.0.10:80           â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  Response: src=10.96.0.10:80, dst=10.244.1.10              â”‚
â”‚     â”‚                                                        â”‚
â”‚     â–¼                                                        â”‚
â”‚  Client Pod receives response                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
                </div>

                <div style="background: #1c4532; color: #9ae6b4; padding: 15px; border-radius: 5px; margin-top: 15px;">
                    <strong>ğŸ’¡ kube-proxy Best Practices:</strong>
                    <ul style="margin-top: 10px; line-height: 2;">
                        <li>Use IPVS mode for large clusters (1000+ services)</li>
                        <li>Monitor kube-proxy logs for errors</li>
                        <li>Use readiness probes to prevent traffic to unhealthy pods</li>
                        <li>Consider service mesh (Istio, Linkerd) for advanced routing</li>
                        <li>Use headless services for direct pod-to-pod communication</li>
                    </ul>
                </div>

                <h4 style="color: #90cdf4; margin-top: 20px;">Troubleshooting kube-proxy:</h4>
                <pre style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 5px; overflow-x: auto;"><code># Check kube-proxy is running
kubectl get pods -n kube-system | grep kube-proxy

# View kube-proxy logs
kubectl logs -n kube-system kube-proxy-xxxxx

# Check iptables rules (iptables mode)
iptables-save | grep KUBE

# Check IPVS rules (IPVS mode)
ipvsadm -Ln

# Test service connectivity
kubectl run test --image=busybox -it --rm -- wget -O- http://nginx-service

# Common issues:
1. Service not accessible
   - Check service exists: kubectl get svc
   - Check endpoints exist: kubectl get endpoints
   - Check kube-proxy is running
   - Check iptables/IPVS rules

2. Load balancing not working
   - Check multiple pods are ready
   - Check session affinity settings
   - Verify kube-proxy mode

3. External access not working (NodePort/LoadBalancer)
   - Check firewall rules
   - Check cloud provider load balancer
   - Verify NodePort is in valid range (30000-32767)</code></pre>
            </div>

            <h3 style="color: #667eea;">3. Container Runtime</h3>
            
            <div style="background: var(--dark-light); padding: 25px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 20px 0;">
                <p><strong>Role:</strong> Software responsible for running containers.</p>
                
                <p><strong>Analogy:</strong> Like the engine that actually runs your car.</p>
                
                <p><strong>Popular runtimes:</strong></p>
                <ul>
                    <li><strong>containerd:</strong> Industry standard, lightweight</li>
                    <li><strong>CRI-O:</strong> Lightweight, designed for Kubernetes</li>
                    <li><strong>Docker:</strong> (deprecated in K8s 1.24+, but still works via containerd)</li>
                </ul>

                <p><strong>What it does:</strong></p>
                <ul>
                    <li>Pulls container images from registries</li>
                    <li>Starts and stops containers</li>
                    <li>Manages container lifecycle</li>
                    <li>Provides container isolation</li>
                </ul>
            </div>

            <h2>ğŸ”„ How Components Communicate</h2>

            <div style="background: #2d3748; color: #e2e8f0; padding: 25px; border-radius: 10px; margin: 30px 0;">
                <h3 style="color: #90cdf4; margin-top: 0;">ğŸ“ Example: Creating a Deployment</h3>
                
                <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto; line-height: 1.6;"><code>1. User runs: kubectl create deployment nginx --image=nginx --replicas=3

2. kubectl â†’ API Server: "Create deployment with 3 nginx replicas"

3. API Server:
   - Authenticates user âœ…
   - Validates request âœ…
   - Stores deployment in etcd
   - Returns success to kubectl

4. Deployment Controller (watching API Server):
   - Detects new deployment
   - Creates ReplicaSet with 3 replicas
   - Stores ReplicaSet in etcd (via API Server)

5. ReplicaSet Controller:
   - Detects new ReplicaSet
   - Creates 3 pod objects
   - Stores pods in etcd (via API Server)

6. Scheduler (watching for unscheduled pods):
   - Finds 3 pods without nodes
   - Evaluates all nodes
   - Assigns pods to nodes (e.g., Node1, Node2, Node3)
   - Updates pod specs in etcd

7. kubelet on Node1 (watching API Server):
   - Sees pod assigned to its node
   - Tells container runtime: "Start nginx container"
   - Container runtime pulls image and starts container
   - kubelet reports pod status to API Server

8. kubelet on Node2 and Node3: (same as step 7)

9. kube-proxy on all nodes:
   - Detects new pods
   - Updates iptables rules for service discovery

10. Result: 3 nginx pods running across 3 nodes! ğŸ‰</code></pre>
            </div>

            <h2>ğŸ’» Hands-On: Explore Your Cluster</h2>

            <p>Let's explore a real Kubernetes cluster and see these components in action!</p>

            <div style="background: #2d3748; color: #e2e8f0; padding: 25px; border-radius: 10px; margin: 30px 0;">
                <h3 style="color: #90cdf4; margin-top: 0;">Step 1: Check Cluster Info</h3>
                <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>kubectl cluster-info

# Output:
# Kubernetes control plane is running at https://127.0.0.1:6443
# CoreDNS is running at https://127.0.0.1:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</code></pre>

                <h3 style="color: #90cdf4;">Step 2: View Nodes</h3>
                <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>kubectl get nodes

# Output:
# NAME           STATUS   ROLES           AGE   VERSION
# minikube       Ready    control-plane   5d    v1.28.0

# Get detailed node info
kubectl describe node minikube</code></pre>

                <h3 style="color: #90cdf4;">Step 3: View Control Plane Components</h3>
                <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>kubectl get pods -n kube-system

# Output shows control plane components:
# NAME                               READY   STATUS    RESTARTS   AGE
# etcd-minikube                      1/1     Running   0          5d
# kube-apiserver-minikube            1/1     Running   0          5d
# kube-controller-manager-minikube   1/1     Running   0          5d
# kube-scheduler-minikube            1/1     Running   0          5d
# kube-proxy-xxxxx                   1/1     Running   0          5d</code></pre>

                <h3 style="color: #90cdf4;">Step 4: Check Component Status</h3>
                <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>kubectl get componentstatuses

# Output:
# NAME                 STATUS    MESSAGE   ERROR
# scheduler            Healthy   ok
# controller-manager   Healthy   ok
# etcd-0               Healthy   ok</code></pre>

                <h3 style="color: #90cdf4;">Step 5: View API Server Logs</h3>
                <pre style="background: #1a202c; padding: 15px; border-radius: 5px; overflow-x: auto;"><code>kubectl logs -n kube-system kube-apiserver-minikube | tail -20

# You'll see API requests being processed!</code></pre>
            </div>

            <h2>ğŸ¯ Key Takeaways</h2>

            <div style="background: #1c4532; color: #9ae6b4; padding: 25px; border-radius: 10px; margin: 30px 0;">
                <ul style="line-height: 2; font-size: 1.05rem;">
                    <li>âœ… <strong>Control Plane</strong> = Brain (makes decisions)</li>
                    <li>âœ… <strong>Worker Nodes</strong> = Muscle (runs workloads)</li>
                    <li>âœ… <strong>API Server</strong> = Central hub for all communication</li>
                    <li>âœ… <strong>etcd</strong> = Database storing cluster state</li>
                    <li>âœ… <strong>Scheduler</strong> = Assigns pods to nodes</li>
                    <li>âœ… <strong>Controllers</strong> = Maintain desired state</li>
                    <li>âœ… <strong>kubelet</strong> = Node agent managing pods</li>
                    <li>âœ… <strong>kube-proxy</strong> = Network proxy for services</li>
                </ul>
            </div>

            <h2>ğŸš€ What's Next?</h2>

            <p>Now that you understand Kubernetes architecture, it's time to get hands-on! In the next tutorial, we'll set up your first Kubernetes cluster and deploy your first application.</p>

            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; text-align: center; margin: 40px 0;">
                <h3 style="color: white; margin-top: 0;">Ready to build your cluster?</h3>
                <a href="03-setting-up-cluster.html" style="display: inline-block; background: var(--dark-light); color: #667eea; padding: 15px 40px; border-radius: 8px; text-decoration: none; font-weight: 600; margin-top: 15px;">
                    Tutorial #3: Setting Up Your First Cluster â†’
                </a>
            </div>

            <hr style="margin: 40px 0;">
            
            <div style="text-align: center; color: #718096;">
                <p>Questions? Connect with me on <a href="https://www.linkedin.com/in/saransh-jain13/" target="_blank" style="color: #667eea;">LinkedIn</a> or <a href="https://github.com/Saransh138" target="_blank" style="color: #667eea;">GitHub</a>!</p>
            </div>
            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <h3><span class="brand-icon">âš¡</span> DevSecOpsSolution<span class="highlight">.in</span></h3>
                    <p>Building secure, scalable cloud solutions</p>
                </div>
                <div class="footer-links">
                    <h4>Quick Links</h4>
                    <ul>
                        <li><a href="../index.html#home">Home</a></li>
                        <li><a href="../k8s-tutorials.html">K8s Tutorials</a></li>
                        <li><a href="../blog.html">Blog</a></li>
                    </ul>
                </div>
                <div class="footer-social">
                    <h4>Connect</h4>
                    <div class="social-links">
                        <a href="https://github.com/Saransh138" target="_blank"><i class="fab fa-github"></i></a>
                        <a href="https://www.linkedin.com/in/saransh-jain13/" target="_blank"><i class="fab fa-linkedin"></i></a>
                    </div>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2024 DevSecOps Solutions. All rights reserved.</p>
            </div>
        </div>
    </footer>

    <script src="../script.js"></script>
</body>
</html>
